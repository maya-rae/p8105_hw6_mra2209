---
title: 'P8105 HW6'
author: "Maya Arnott"
date: "2025-11-29"
output: github_document
---

```{r, include = FALSE, message = FALSE, warning = FALSE}
library(tidyverse)
library(broom)
library(dplyr)
library(forcats)
library(car)
library(MASS)
library(modelr)
library(purrr)
library(glmnet)

knitr::opts_chunk$set(
  echo = TRUE,
  warning = FALSE,
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
  )

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

set.seed(123)
```

# Problem 1: Taking a closer look at the Washington Post homicide data.

First, I'll load and tidy the homicide data.
```{r}
homicide_df = 
  read_csv("./data/homicide-data.csv") |> 
  janitor::clean_names()
```

Creating a `city_state` variable and binary variable for homicide solved/unsolved.
```{r}
homicide_df = homicide_df |> 
  mutate(
    # creating a city, state var
    city_state = paste(city, state, sep = ", "),
    # creating a binary case_solved var
    # 1 = case solved and 0 = case not solved/anything else
    case_solved = ifelse(grepl("^Closed by arrest", disposition), 1, 0),
    # converting age var to numeric
    victim_age = as.numeric(victim_age),
    # converting victim's sex and race to factor vars
    victim_sex = as.factor(victim_sex),
    victim_race = as.factor(victim_race)
  ) |>
  # using only data when race = white or black 
  filter (
    victim_race %in% c("White", "Black")
  ) 

homicide_df = homicide_df |> 
  dplyr::select(-city, -state) |> 
  filter(
    !city_state %in% c("Phoenix, AZ", "Kansas City, MO", "Dallas, TX", "Tulsa, AL")
  )
```

I will make a `glm` function.

```{r}
baltimore_df = homicide_df |> 
  filter(city_state == "Baltimore, MD")

balt_glm = 
  glm(case_solved ~ victim_age + victim_sex + victim_race, 
      data = baltimore_df,
      family = binomial(link = "logit")
      )
summary(balt_glm)
```

I will tidy my glm function.

```{r}
tidy_glm = 
  broom::tidy(balt_glm, conf.int = TRUE, exponentiate = TRUE)

tidy_glm |> 
  filter(term == "victim_sexMale") |> 
  dplyr::select(term, estimate, conf.low, conf.high)

```

According to this logistic regression model, this means that the male victims have 57.4% lower odds of having their homicide cases solved than female victims when all other predictors are held constant. This odds ratio has a confidence interval of 0.324 to 0.558. Since the confidence interval does not include 1, this difference is statistically signi
ficant at the 0.05 level.

Now, I will run `glm` for all the cities and extract their adjusted odds ratios.

```{r}
city_results = homicide_df |> 
  group_by(city_state) |> 
  # nest data for purrr
  nest() |> 
  mutate(
    glm_model = map(data, ~ glm(
      case_solved ~ victim_age + victim_sex + victim_race,
      data = .x,
      family = binomial(link = "logit")
      )),
    tidy_glm = map(glm_model, ~tidy(.x, conf.int = TRUE, exponenitate = TRUE))
  ) |> 
  dplyr::select(city_state, tidy_glm) |> 
  # expand the results by unnesting
  unnest(tidy_glm)

```

Now, I will only extract the male vs female adjusted odds ratios and make a table of the results.

```{r}
OR_sex_by_city = city_results |> 
  filter(term == "victim_sexMale") |> 
  dplyr::select(city_state, estimate, conf.low, conf.high) |> # ensuring the column stores actual ods ratios
  mutate(
    OR = exp(estimate),
    lower_CI = exp(conf.low),
    upper_CI = exp(conf.high)
  ) |> 
  dplyr::select(-estimate, -conf.low, -conf.high)
```

Creating a plot of ORs by City, State.

```{r, fig.width=12, fig.height=12}
# plot the data
ggplot(OR_sex_by_city, aes(
  x = OR, 
  y = fct_reorder(city_state, OR))
  ) +
  geom_point() +
  geom_errorbarh(aes(xmin = lower_CI, xmax = upper_CI)) +
  labs(
    x = "Adjusted Odds Ratio (Male vs Female)",
    y = "City, State",
    title = "Adjusted Odds Ratio of Solved Homicide Cases by Sex and City ",
    caption = "Error bars show 95% confidence levels from glm function"
  )

```

Albuquerque, NM has the greatest adjusted odds ratio of male homicide cases solved vs female homicide cases solved, followed by Stockton, California and Fresno, California. Male homicide victims in Albuquerque, NM have 1.76 times the odds of having their case solved compared to female victims, according to this model. Although, I cannot conclude that the true odds truly differ between males and females because the confidence interval includes 1. These three cities also happen to have the largest confidence intervals.

The three cities with the greatest adjusted odds ratios of female homicides solved vs male homicide cases solved is New York, NY, Baton Rouge, LA, and Omaha, NE, respectively. In New York, NY, the odds of solving homicides involving male victims are 74% lower than those involving female victims, according to this model. The confidence interval's for these three cities do not include 1, and can be seen as statistically significant. 

# Problem 2: Bootstrapping in Central Park!

Importing the data.
```{r}
library(p8105.datasets)
data("weather_df")
```

Let's write our simple linear regression function.

```{r}
weather_lm = lm(tmax ~ tmin + prcp, data = weather_df)
summary(weather_lm)
```

Now I am going to refit the model 5,000 times, and resample the data with replacement each time, extracting the key quantities. 

```{r}
boot_results = map_dfr(1:5000, function(i) {
  
  boot_sample = weather_df[sample(nrow(weather_df), replace = TRUE),]
  
  fit = lm(tmax ~ tmin + prcp, data = boot_sample)
  
  tidy_fit = tidy(fit)
  glance_fit = glance(fit)
  
  tibble(
    r2 = glance_fit$r.squared,
    beta1 = tidy_fit$estimate[tidy_fit$term == "tmin"],
    beta2 = tidy_fit$estimate[tidy_fit$term == "prcp"],
  )
})

boot_results
```

I will plot the distributions of the estimates.

```{r}

# plotting beta1
ggplot(boot_results, aes(x = beta1)) +
 geom_histogram(bins = 40, fill = "darkblue", color = "blue") +
  labs(
    title = "Boostrap Distributions of Beta1 (tmin)",
    x = "Beta1 (tmin coefficient)",
    y = "Frequency"
  )
 
# plotting beta2
ggplot(boot_results, aes(x = beta2)) +
 geom_histogram(bins = 40, fill = "darkblue", color = "blue") +
  labs(
    title = "Boostrap Distributions of Beta2 (prcp)",
    x = "Beta2 (prcp coefficient)",
    y = "Frequency"
  )

# plotting R^2
ggplot(boot_results, aes(x = r2)) +
 geom_histogram(bins = 40, fill = "darkblue", color = "blue") +
  labs(
    title = "Boostrap Distributions of R Squared",
    x = "R Squared",
    y = "Frequency"
  )

```

The distribution of Beta1 is roughly normally distributed and is centered around 1.015, which is close to the original estimate of the tmin coefficient in my `weather_lm` linear regression model. The distribution of Beta2 is also roughly normally distributed and is centered around -0.006, which is also close to my original estimate of the prcp coefficient in my `weather_lm` linear regression model. This suggests that the model is relatively stable. The distribution of R Squared is more left skewed, indicating that in some bootstrap samples the model explained less variance than the original estimate. Although, the width of the distribution was narrow and was centered around 0.950, indicating that the linear model explains approximately 95% of the variance in tmax across bootstrap samples.

# Problem 3: Regression modeling for child birthweight

First, I will load and tidy the birtweight dataset.

```{r}
birthweight_df = 
  read_csv("./data/birthweight.csv") |> 
  janitor::clean_names()
```

Right now, all variables are numeric, but `babysex` `frace` `mrace` and `malform` should be turned into factors. 

```{r}
birthweight_df = birthweight_df |> 
  mutate(
    babysex = factor(babysex, labels = c("Male", "Female")),
    frace   = factor(frace,
                     levels = c(1, 2, 3, 4, 8, 9),
                     labels = c("White", "Black", "Asian", "Puerto Rican",
                                "Other", "Unknown")), 
    mrace   = factor(mrace,
                     levels = c(1, 2, 3, 4, 8),
                     labels = c("White", "Black", "Asian", "Puerto Rican",
                                "Other")),
    malform = factor(malform, labels = c("absent", "present"))
  )

birthweight_df = birthweight_df |> 
  # removing variables that have colinearity
  dplyr::select(-delwt, -ppbmi, -pnumlbw, -pnumsga) |> 
  # drop unused levels/collapse small categories
  mutate(
    frace = fct_drop(frace), 
    mrace = fct_drop(mrace)
  ) 
```

I will propose a regression model for birthweight.

I am going to fit a full model first and check for multicollinearity.

```{r}
full_model = lm(bwt ~ . , data = birthweight_df)
summary(full_model)

# double checking any variables that are perfectly collinear with other predictors
alias(lm(bwt ~ ., data = birthweight_df))

# checking multicollinearity
vif(full_model)
```

Now I can see the potential significant predictors for my model. When using `vif()` to assess multicollinearity, most variables have a GVIF^(1/(2*Df)) value between 1 and 3 signifying mild to low correlation. `frace` and `mrace` have the highest GVIF^(1/(2Df)) value, but this is not critical, but is something to note when interpreting these race coefficients in my model.

I am going to use AIC-based stepwise selection to interpret the coefficients because the multicollinerity is not severe and this method will work efficiently for this size and number of predictors.

```{r}
step_model = stepAIC(
  full_model, 
  direction = "both", # this allows variables to both enter or leave
  trace = TRUE       # so I can clearly see the stepwise process
)

summary(step_model)

# check multicollinearity again
vif(step_model)
```

This stepwise selected model has an R squared value of 0.7173, meaning that 72% of the variance in birthweight can be explained by these predictors, accounting for the number of predictors. The low F-statistic also tells us that the model as a whole is highly significant. The strongest effects on birthweight are baby size measurements (`bhead` and `blength`), maternal measurements and behaviors (`wtgain` and `smoken`), maternal race (particularly `mraceBlack` and `mracePuerto Rican`), and gestational age (`gaweeks`).

Now, I will check the model diagnostics.

```{r}
par(mfrow = c(2, 2))
plot(step_model)

stepwise_formula = formula(step_model)
```


I am going to plot the residuals vs fitted values using `add_predictions()` and `add_residuals()`.

```{r}
# adding predictions and residuals to df
birthweight_df2 = birthweight_df |> 
  add_predictions(step_model, var = "predicted_bwt") |> 
  add_residuals(step_model, var = "residuals")

# plotting residuals vs fitted values
ggplot(birthweight_df2, aes(x = predicted_bwt, y = residuals)) +
  geom_point(alpha = 0.5) +
  geom_hline(yintercept = 0, color = "blue", linetype = "dashed") +
  labs(
    x = "Fitted values (predicted birthweight)",
    y = "Resdiuals",
    title = "Residuals vs Fitted Values",
    caption = "Blue dashed line = perfect prediction"
  )
```

A good residual plot should have residuals that are randomly scattered around 0 with no systematic pattern. The residuals in this plot are not perfectly randomly scattered and the variance of residuals seems a bit smaller for lower fitted values and larger for higher fitted values. There are also a couple of outliers at the lower predicted birthweights. Overall, most residuals are close to zero and captures the central trend reasonably well, but may be violating the constant variance assumption.

Now, I will compare my model to two others.

```{r}
# first model for comparison (simple main effects)
main_effects_formula = bwt ~ blength + gaweeks

# second model for comparison (with all interactions)
interactions_formula = bwt ~ (bhead + blength + babysex)^3

```

I will use `crossv_mc()` to create cross-validation splits. Then, I will compute the prediction errors.

```{r}
cv_df = 
  crossv_mc(birthweight_df, 50) |> 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble)
  )

cv_rmse <- function(train, test, formula) {
  # fit model safely
  model <- tryCatch(lm(formula, data = train), error = function(e) NULL)
  if(is.null(model)) return(NA_real_)
  
  # align factor levels in test
  for(col in names(test)) {
    if(is.factor(train[[col]])) {
      test[[col]] <- factor(test[[col]], levels = levels(train[[col]]))
    }
  }
  
  # predict safely
  preds <- tryCatch(predict(model, newdata = test),
                    error = function(e) rep(NA_real_, nrow(test)))
  
  valid <- !is.na(preds) & !is.na(test$bwt)
  if(sum(valid) == 0) return(NA_real_)
  
  sqrt(mean((test$bwt[valid] - preds[valid])^2))
}


# fitting the models to training data
cv_df = cv_df |> 
  mutate(
    stepwise_mod    = map(train, \(df) lm(stepwise_formula, data = df)),
    main_effects_mod = map(train, \(df) lm(bwt ~ blength + gaweeks, data = df)),
    interactions_mod = map(train, \(df) lm(bwt ~ (bhead + blength + babysex)^3, data = df))
  ) |> 
  mutate(
    # compute RMSE on test splits
    rmse_stepwise     = map2_dbl(stepwise_mod, test, \(mod, df) {
      df <- df |> mutate(across(where(is.factor), ~factor(.x, levels = levels(df))))
      sqrt(mean((df$bwt - predict(mod, newdata = df))^2))
    }),
    rmse_main_effects = map2_dbl(main_effects_mod, test, \(mod, df) {
      df <- df |> mutate(across(where(is.factor), ~factor(.x, levels = levels(df))))
      sqrt(mean((df$bwt - predict(mod, newdata = df))^2))
    }),
    rmse_interactions = map2_dbl(interactions_mod, test, \(mod, df) {
      df <- df |> mutate(across(where(is.factor), ~factor(.x, levels = levels(df))))
      sqrt(mean((df$bwt - predict(mod, newdata = df))^2))
    })
  )
```

I will summarize the results in this ggplot. I am confused as to why I cannot compute the RMSE for my stepwise and interactions models using this workflow. I tried to exclude Na values and align the factor levels, but nothing worked. I can only see the main_effects data in my plot below.

```{r}
cv_df |> 
  dplyr::select(starts_with("rmse")) |> 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") |> 
  mutate(model = fct_inorder(model)) |> 
  ggplot(aes(x = model, y = rmse)) + geom_violin()

```

I will use ridge regression cross-validation to compare the three models and compute their RMSEs.

```{r}
# prepare design matrices

# stepwise model
stepwise_formula = bwt ~ babysex + bhead + blength + fincome + gaweeks + 
                    mheight + mrace + parity + ppwt + smoken + wtgain
x_stepwise = model.matrix(stepwise_formula, data = birthweight_df)[,-1]

# main effects model
main_effects_formula = bwt ~ blength + gaweeks
x_main = model.matrix(main_effects_formula, data = birthweight_df)[,-1]

# interactionsmodel
interactions_formula = bwt ~ (bhead + blength + babysex)^3
x_inter = model.matrix(interactions_formula, data = birthweight_df)[,-1]

# Response
y = birthweight_df$bwt

cv_ridge_rmse = function(x, y, nfolds = 10) {
  set.seed(123)
  cvfit = cv.glmnet(x, y, alpha = 0, nfolds = nfolds)
  # predict on full data using lambda.min
  preds = predict(cvfit, newx = x, s = "lambda.min")
  sqrt(mean((y - preds)^2))
}

rmse_values = tibble(
  model = c("stepwise", "main_effects", "interactions"),
  rmse  = c(
    cv_ridge_rmse(x_stepwise, y),
    cv_ridge_rmse(x_main, y),
    cv_ridge_rmse(x_inter, y)
  )
)

print(rmse_values)

```

My stepwise model has the lowest RMSE value of 272, meaning, on average, the predictions are off by about 272 grams from the true birthweight. Out of these models, the stepwise one has the best predictive accuracy. It is also the model with the highest adjusted R squared value.