---
title: 'P8105 HW6'
author: "Maya Arnott"
date: "2025-11-29"
output: github_document
---

```{r, include = FALSE, message = FALSE, warning = FALSE}
library(tidyverse)
library(broom)
library(dplyr)
library(forcats)

knitr::opts_chunk$set(
  echo = TRUE,
  warning = FALSE,
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
  )

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

set.seed(123)
```

# Problem 1: Taking a closer look at the Washington Post homicide data.

First, I'll load and tidy the homicide data.
```{r}
homicide_df = 
  read_csv("./data/homicide-data.csv") |> 
  janitor::clean_names()
```

Creating a `city_state` variable and binary variable for homicide solved/unsolved.
```{r}
homicide_df = homicide_df |> 
  mutate(
    # creating a city, state var
    city_state = paste(city, state, sep = ", "),
    # creating a binary case_solved var
    # 1 = case solved and 0 = case not solved/anything else
    case_solved = ifelse(grepl("^Closed by arrest", disposition), 1, 0),
    # converting age var to numeric
    victim_age = as.numeric(victim_age),
    # converting victim's sex and race to factor vars
    victim_sex = as.factor(victim_sex),
    victim_race = as.factor(victim_race)
  ) |>
  # using only data when race = white or black 
  filter (
    victim_race %in% c("White", "Black")
  ) 

homicide_df = homicide_df |> 
  select(-city, -state) |> 
  filter(
    !city_state %in% c("Phoenix, AZ", "Kansas City, MO", "Dallas, TX", "Tulsa, AL")
  )
```

I will make a `glm` function.

```{r}
baltimore_df = homicide_df |> 
  filter(city_state == "Baltimore, MD")

balt_glm = 
  glm(case_solved ~ victim_age + victim_sex + victim_race, 
      data = baltimore_df,
      family = binomial(link = "logit")
      )
summary(balt_glm)
```

I will tidy my glm function.

```{r}
tidy_glm = 
  broom::tidy(balt_glm, conf.int = TRUE, exponentiate = TRUE)

tidy_glm |> 
  filter(term == "victim_sexMale") |> 
  select(term, estimate, conf.low, conf.high)

```

According to this logistic regression model, this means that the male victims have 57.4% lower odds of having their homicide cases solved than female victims when all other predictors are held constant. This odds ratio has a confidence interval of 0.324 to 0.558. Since the confidence interval does not include 1, this difference is statistically signi
ficant at the 0.05 level.

Now, I will run `glm` for all the cities and extract their adjusted odds ratios.

```{r}
city_results = homicide_df |> 
  group_by(city_state) |> 
  # nest data for purrr
  nest() |> 
  mutate(
    glm_model = map(data, ~ glm(
      case_solved ~ victim_age + victim_sex + victim_race,
      data = .x,
      family = binomial(link = "logit")
      )),
    tidy_glm = map(glm_model, ~tidy(.x, conf.int = TRUE, exponenitate = TRUE))
  ) |> 
  select(city_state, tidy_glm) |> 
  # expand the results by unnesting
  unnest(tidy_glm)

```

Now, I will only extract the male vs female adjusted odds ratios and make a table of the results.

```{r}
OR_sex_by_city = city_results |> 
  filter(term == "victim_sexMale") |> 
  select(city_state, estimate, conf.low, conf.high) |> # ensuring the column stores actual ods ratios
  mutate(
    OR = exp(estimate),
    lower_CI = exp(conf.low),
    upper_CI = exp(conf.high)
  ) |> 
  select(-estimate, -conf.low, -conf.high)
```

Creating a plot of ORs by City, State.

```{r, fig.width=12, fig.height=12}
# plot the data
ggplot(OR_sex_by_city, aes(
  x = OR, 
  y = fct_reorder(city_state, OR))
  ) +
  geom_point() +
  geom_errorbarh(aes(xmin = lower_CI, xmax = upper_CI)) +
  labs(
    x = "Adjusted Odds Ratio (Male vs Female)",
    y = "City, State",
    title = "Adjusted Odds Ratio of Solved Homicide Cases by Sex and City ",
    caption = "Error bars show 95% confidence levels from glm function"
  )

```

Albuquerque, NM has the greatest adjusted odds ratio of male homicide cases solved vs female homicide cases solved, followed by Stockton, California and Fresno, California. Male homicide victims in Albuquerque, NM have 1.76 times the odds of having their case solved compared to female victims, according to this model. Although, I cannot conclude that the true odds truly differ between males and females because the confidence interval includes 1. These three cities also happen to have the largest confidence intervals.

The three cities with the greatest adjusted odds ratios of female homicides solved vs male homicide cases solved is New York, NY, Baton Rouge, LA, and Omaha, NE, respectively. In New York, NY, the odds of solving homicides involving male victims are 74% lower than those involving female victims, according to this model. The confidence interval's for these three cities do not include 1, and can be seen as statistically significant. 

# Problem 2: Bootstrapping in Central Park!

Importing the data.
```{r}
library(p8105.datasets)
data("weather_df")
```

Let's write our simple linear regression function.

```{r}
weather_lm = lm(tmax ~ tmin + prcp, data = weather_df)
summary(weather_lm)
```

Now I am going to refit the model 5,000 times, and resample the data with replacement each time, extracting the key quantities. 

```{r}
boot_results = map_dfr(1:5000, function(i) {
  
  boot_sample = weather_df[sample(nrow(weather_df), replace = TRUE),]
  
  fit = lm(tmax ~ tmin + prcp, data = boot_sample)
  
  tidy_fit = tidy(fit)
  glance_fit = glance(fit)
  
  tibble(
    r2 = glance_fit$r.squared,
    beta1 = tidy_fit$estimate[tidy_fit$term == "tmin"],
    beta2 = tidy_fit$estimate[tidy_fit$term == "prcp"],
  )
})

boot_results
```

I will plot the distributions of the estimates.

```{r}

# plotting beta1
ggplot(boot_results, aes(x = beta1)) +
 geom_histogram(bins = 40, fill = "darkblue", color = "blue") +
  labs(
    title = "Boostrap Distributions of Beta1 (tmin)",
    x = "Beta1 (tmin coefficient)",
    y = "Frequency"
  )
 
# plotting beta2
ggplot(boot_results, aes(x = beta2)) +
 geom_histogram(bins = 40, fill = "darkblue", color = "blue") +
  labs(
    title = "Boostrap Distributions of Beta2 (prcp)",
    x = "Beta2 (prcp coefficient)",
    y = "Frequency"
  )

# plotting R^2
ggplot(boot_results, aes(x = r2)) +
 geom_histogram(bins = 40, fill = "darkblue", color = "blue") +
  labs(
    title = "Boostrap Distributions of R Squared",
    x = "R Squared",
    y = "Frequency"
  )

```

The distribution of Beta1 is roughly normally distributed and is centered around 1.015, which is close to the original estimate of the tmin coefficient in my `weather_lm` linear regression model. The distribution of Beta2 is also roughly normally distributed and is centered around -0.006, which is also close to my original estimate of the prcp coefficient in my `weather_lm` linear regression model. This suggests that the model is relatively stable. The distribution of R Squared is more left skewed, indicating that in some bootstrap samples the model explained less variance than the original estimate. Although, the width of the distribution was narrow and was centered around 0.950, indicating that the linear model explains approximately 95% of the variance in tmax across bootstrap samples.

# Problem 3: Regression modeling for child birthweight

Loading and tidying the data.

```{r}

```



